{
  "hash": "e74b47aea08578aa3ab7e67c93d52719",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"BIOPOLE - Chukchi Sea metatranscriptomics analysis report\"\nauthor: \"Nathan\"\noutput-file: index.html\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    theme: cosmo\n    code-fold: true\n    code-block-bg: true\neditor: source\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n<style>\npre code {\n  background-color: #f2f2f2 !important;\n  display: block;\n  padding: 0.8em;\n  border-radius: 6px;\n}\ncode {\n  background-color: #f2f2f2 !important;\n  padding: 0.15em 0.35em;\n  border-radius: 4px;\n}\n</style>\n\nThis report summarises the bioinformatics workflow applied to the Chukchi Sea eRNA samples to study the Nitrogen cycles, particularly the denitrifcation and anammox metabolic pathways, using metatranscriptomics approach.\n\n## ðŸ§ª Sample Processing, Sequencing & Data Availability\n\nThe Centre for Genomic Research (CGR) processed **9 marine eRNA samples** (+ 1 negative control) for metatranscriptomic sequencing as part of project **SSP203072**. The workflow included:\n\n- DNase treatment of all extracted RNA samples.\n\n- rRNA depletion using the *Seawater riboPOOL* kit.\n\n- Construction of **Illumina RNA-seq libraries** from the rRNA-depleted material.\n\nMultiplexing of all libraries and sequencing on one lane of an **Illumina NovaSeq X Plus** (NovaSeq X+) 25B flow cell.\n\nThis setup is expected to produce approximately **~325 million read pairs per sample**, providing deep metatranscriptomic coverage suitable for resolving nitrogen-cycling pathways, including denitrification and anammox.\n\n**Funding & administrative details:**\n\n- **SSP ID**: SSP203072\n\n- **Platform**: Illumina NovaSeq X+\n\n- **Funding**: NEOF1819 â€” Purchase Order P11212-200\n\nAll filesâ€”including raw data, processing details, and download instructionsâ€”are available via:\n\n[Project data download](https://cgr.liv.ac.uk/illum/SSP203072_b7beb589a74e3e61/)\n\n## ðŸ“Š Sequencing Output & CGR QC Summary\n\n| Name                                                                 | Raw Reads (M) | Trimmed Reads (M) | Raw Bases (M) | Trimmed Bases (M) |\n|----------------------------------------------------------------------|---------------|--------------------|----------------|--------------------|\n| 1-S4S                                                                | 422.03        | 418.30             | 126,608.75     | 120,507.35         |\n| 2-S4M                                                                | 559.84        | 557.67             | 167,952.06     | 163,451.31         |\n| 3-S4B                                                                | 613.03        | 611.42             | 183,908.71     | 179,372.50         |\n| <span style=\"color:red;\">4-S13S</span>                               | 9.89          | 7.81               | 2,968.42       | 2,244.11           |\n| 5-S13M                                                               | 240.41        | 238.67             | 72,124.26      | 70,520.45          |\n| 6-S13B                                                               | 617.78        | 615.94             | 185,334.01     | 181,063.09         |\n| 7-S14S                                                               | 526.76        | 524.35             | 158,026.71     | 153,976.49         |\n| 8-S14M                                                               | 526.33        | 524.19             | 157,899.00     | 153,074.61         |\n| 9-S14B                                                               | 571.17        | 569.59             | 171,349.89     | 166,325.31         |\n| <span style=\"color:red;\">10-negative_control</span>                  | 5.92          | 5.16               | 1,776.58       | 1,487.48           |\n\n**Description of Methods**\nThe raw FASTQ files are trimmed for the presence of Illumina adapter sequences using Cutadapt version 4.5 . The option -O 3 was used, meaning that trimming occurred in reads where at least 3bp of adapter sequence was observed at the 3' end of the read. The reads were further trimmed to remove low quality bases with a minimum window quality score of 20. After trimming, reads shorter than 15 bp were removed. Only read pairs are retained, therefore if a read of a pair is trimmed away then the other read in the pair is also discarded.\n\n::: {.callout-note title=\"ðŸ“ Notes on Low-Yield Samples\"}\n**4-S13S** returned an exceptionally low number of reads because very little RNA was recovered from the corresponding Sterivex filters. This limited input material resulted in poor library complexity and low overall sequencing yield.\n\n**10-negative_control** is a processing negative control sample and therefore contains no biological RNA. The very low read count is expected and confirms that minimal contamination occurred during library preparation.\n:::\n\n# ðŸ§ª Bioinformatics Workflow\n\n## rRNA Removal â€“ **SortMeRNA**\n\nTo enrich for mRNA and other non-rRNA transcripts, we removed ribosomal RNA using **SortMeRNA**.\n\nThe command below shows the SortMeRNA run that was used for each sample. We used the CGR-trimmed paired-end reads as input and the **smr_v4.3_sensitive_db_rfam_seeds** database for rRNA identification.\n\n```{bash}\n\nsortmerna \\\n  --ref \"smr_v4.3_sensitive_db_rfam_seeds.fasta\" \\\n  --reads \"$R1\" \\\n  --reads \"$R2\" \\\n  --threads \"$SLURM_CPUS_PER_TASK\" \\\n  --fastx \\\n  --out2 \\\n  --paired_in \\\n  --aligned \"${SAMPLE}_rRNA\" \\\n  --other \"${SAMPLE}_RNA_clean\" \\\n  --workdir \"$WORKDIR\"\n``` \n\nFor each sample, SortMeRNA produces:\n\n*_rRNA_* files containing reads classified as rRNA\n\n*_RNA_clean_* files containing the rRNA-depleted read pairs, which are carried forward to assembly.\n\n## De Novo Assembly â€“ **MEGAHIT**\n\nWe performed a co-assembly of selected rRNA-depleted samples using MEGAHIT, optimised for complex metatranscriptomic data with the meta-sensitive preset. For illustration, the command below shows the co-assembly of samples:\n\n```{bash}\nmegahit \n-1 [station_samples]_RNA_clean_fwd.fq.gz \n-2 [station_samples]_RNA_clean_rev.fq.gz \n-t 60 \n--presets meta-sensitive \n--min-contig-len 500 \n-m 0.9 \n-o St[1:3]_megahit_out\n```\n\nAssembly statistics for an example MEGAHIT run (St1) were obtained using seqkit:\n\n```{bash}\nseqkit stats final.contigs.fa\n```\n\nFor example (St1 assembly):\n\n| Assembly           | # Contigs | Total Length (bp) | Min Length (bp) | Mean Length (bp) | Max Length (bp) |\n| ------------------ | --------- | ----------------- | --------------- | ---------------- | --------------- |\n| `final.contigs.fa` | 1,432,902 | 1,457,453,119     | 500             | 1,017.1          | 106,426         |\n\nThese statistics indicate a highly fragmented but deep assembly, typical of complex marine microbial metatranscriptomes, with contigs â‰¥500 bp retained for downstream analyses.\n\n## Read Mapping â€“ **Bowtie2** and **Samtools**\n\nTo quantify transcript coverage across assembled contigs, we mapped the rRNA-depleted reads back to the MEGAHIT assembly using Bowtie2, followed by BAM processing with Samtools.\n\nFirst, we built a Bowtie2 index from the fixed assembly:\n\n```{bash}\nbowtie2-build St1_assembly-fixed.fa St1_assembly-fixed\n```\n\nThen, for each sample, paired-end reads were aligned and processed as follows:\n\n```{bash}\nIDX=\"St1_assembly-fixed\"\nR1=\"SAMPLE_RNA_clean_fwd.fq.gz\"\nR2=\"SAMPLE_RNA_clean_rev.fq.gz\"\nTHREADS=16\nOUT=\"St1_SAMPLE\"\n\nMap paired-end reads\n\nbowtie2 -x \"${IDX}\"\n-1 \"${R1}\"\n-2 \"${R2}\"\n-p \"${THREADS}\"\n-S \"${OUT}.sam\"\n\nConvert to BAM, keep mapped reads only (-F 4), sort and index\n\nsamtools view -F 4 -bS \"${OUT}.sam\" -o \"${OUT}-RAW.bam\"\nsamtools sort -@ \"${THREADS}\" \"${OUT}-RAW.bam\" -o \"${OUT}.bam\"\nsamtools index \"${OUT}.bam\"\n```\n\nThe resulting sorted and indexed BAM files (*.bam, *.bam.bai) are used as input for downstream coverage estimation and gene- or contig-level quantification in anviâ€™o.\n\n## Creating anviâ€™o Databases\n\nSubsequent steps involved importing the assemblies and mapped reads into anviâ€™o to facilitate contig profiling, annotation, and interactive exploration of nitrogen-cycle genes (e.g. denitrification and anammox pathways).\n\nIn brief, the workflow included:\n\n1. Creating a contigs database from the MEGAHIT assembly\n\n2. Running HMMs and functional annotation (e.g. PFAM, TIGRFAMs, KOfam)\n\n3. Profiling BAM files for each sample to obtain coverage and detection statistics\n\n4. Merging profiles across samples for joint inspection and downstream analyses\n\nExample (commands will vary slightly depending on environment and anvio version):\n\n\n1. Create contigs database\n```{bash}\nanvi-gen-contigs-database -f St1_assembly-fixed.fa -o St1_contigs.db -n \"St1 Chukchi Sea metaT\"\n```\n2. Run HMMs (standard anvio collection)\n```{bash}\nanvi-run-hmms -c St1_contigs.db --num-threads 20\n```\n3. Profile each BAM file\n```{bash}\nanvi-profile -i St1_SAMPLE.bam -c St1_contigs.db\n--output-dir St1_SAMPLE_profile\n--num-threads 20\n```\n4. Merge profiles across samples\n```{bash}\nanvi-merge St1_*_profile/PROFILE.db -o St1_merged_profiles -c St1_contigs.db\n```\n\nThese anviâ€™o databases form the basis for functional annotation and visualisation of key nitrogen-cycle pathways in the Chukchi Sea metatranscriptomes.\n\n## ðŸ” Functional Annotation of genes\n\nTo characterise the metabolic potential represented in the metatranscriptomic assembly, we performed extensive functional annotation of the anviâ€™o contigs database. This step links assembled sequences to known protein families, orthologous groups, and taxonomic markers, enabling downstream interpretation of nitrogen-cycle genes (e.g., denitrification, anammox).\n\nWe used the following anviâ€™o annotation programs:\n\n```{bash}\nanvi-run-hmms\n```\nIdentifies single-copy core genes (SCGs) and key conserved protein families using anviâ€™oâ€™s curated HMM collections. This provides quality metrics for assemblies and forms the basis for taxonomic inference.\n\n```{bash}\nanvi-run-ncbi-cogs\n```\nAssigns Clusters of Orthologous Groups (COGs) from NCBI to contigs based on predicted open reading frames. COG categories help identify broad functional roles such as energy production, amino acid metabolism, stress response, etc.\n```{bash}\nanvi-run-kegg-kofams\n```\nAnnotates genes using KEGG Orthologs (KOfam HMMs), providing pathway-level information including nitrogen cycling modules (e.g., nitrate reduction, nitrification, denitrification, anammox).\n```{bash}\nanvi-run-scg-taxonomy\n```\nUses single-copy core gene content to infer taxonomic origin of contigs, giving insight into which microbial groups are contributing to specific nitrogen-cycling pathways.\n\n## ðŸ”¬ Metabolic Reconstruction and Pathway Visualisation\n\nFollowing functional annotation, we performed metabolic inference and pathway-level analysis using anviâ€™oâ€™s metabolism suite. These tools integrate KEGG Ortholog (KOfam) annotations with curated pathway models to identify which biochemical pathways are represented in the dataset and to visualise how transcripts map onto specific metabolic processesâ€”particularly those involved in nitrogen cycling.\n\nWe used the following anviâ€™o programs:\n```{bash}\nanvi-estimate-metabolism\n```\nIdentifies complete and partial KEGG modules across all annotated contigs, providing an overview of metabolic potential (e.g., denitrification, dissimilatory nitrate reduction, anammox).\n```{bash}\nanvi-react-network\n```\nGenerates reaction-centric metabolic networks based on KEGG reactions detected in the assembly. This allows exploration of how individual reactions connect into broader nitrogen pathways.\n```{bash}\nanvi-reaction-network\n```\nCreates interactive network files linking genes (KO identifiers), reactions, and pathwaysâ€”useful for mapping expression levels or identifying pathway bottlenecks.\n```{bash}\nanvi-draw-kegg\n```\nRenders KEGG metabolic pathway diagrams annotated with detected genes, enabling visual inspection of pathway completeness and highlighting which steps are supported by metatranscriptomic evidence.\n\nThese tools collectively provide a pathway-level view of nitrogen cycling activity in the Chukchi Sea microbial community, enabling detailed interpretation of expression patterns associated with denitrification, nitrification, and anammox processes.\n\n## KEGG Module M00529 â€” Denitrification (nitrate â†’ nitrogen)\n\n![KEGG module M00529 (Denitrification, nitrate â†’ nitrogen). Diagram from https://www.genome.jp/dbget-bin/www_bget?md:M00529](BIOPOLE_Chukchi_metaT_files/KEGG_Module_Denitrification_M00529.png){width=75%}\n\nFrom the output of anvi-estimate-metabolism, we can look for the KEGG module for Denitrification (M00529) and look at its completeness:\n\n| KEGG Module | Station   | stepwise_module_completeness | pathwise_module_completeness |\n|------------|-----------|--------------|------------|\n| M00529     | Station_1 | 1.00         | 1.00       |\n| M00529     | Station_2 | 1.00         | 1.00       |\n| M00529     | Station_3 | 1.00         | 1.00       |\n\nSo all the genes required for denitrification to occur seem to be detected at each of the stations.\n\nLet's look at the denitrification pathway in more details using anvi-interactive, so we can see the coverage of the genes involved in denitrification across the 3 depths in the stations.\n\nFirst, we need to create an anvi'o collection that contains all the denitrification genes. Using **anvi-export-functions** we can get the *gene_callers_ids* matching your *KO IDs*, then we can get the contigs name using **anvi-export-table --table genes_in_contigs**. After that we need to use *join* to find the contigs that have the genes of interest and finally we need to add \"_split_00001\" to each contig name (because in this case each contig has only one split as these come from metaT assembly. We ad a column with the name of our bin and then can import that using **anvi-import-collection** \n\n```{bash}\nanvi-export-functions   -c St1_contigs.db   -o St1_gene_functions.tsv\nanvi-export-table --table genes_in_contigs -o St1_genes_in_contigs.tsv St1_contigs.db\ntail -n +2 St1_genes_in_contigs.tsv | cut -f1,2 > gene_to_contig.tsv\n\n# KO list for denitrification (edit/add as needed)\nKOS='K00370|K00371|K00374|K02567|K02568|K04561|K02305'\n# Get unique gene_callers_id hits for those KOs\nawk -F'\\t' -v kos=\"$KOS\" '($3 ~ kos){print $1}' St1_gene_functions.tsv   | sort -u > genes_of_interest.ids\njoin -t $'\\t' genes_of_interest.ids gene_to_contig.tsv   | cut -f2   | sort -u > contigs_of_interest.txt\nawk '{print $1\"_split_00001\\tdenitrification\"}' contigs_of_interest.txt   > denitrification_splits_collection.tsv\n\nanvi-import-collection   -p St1_MERGED/PROFILE.db   -c St1_contigs.db   -C denitrification_splits denitrification_splits_collection.tsv\n```\nNow that we have an anvio collection, we need to \"split\" it from the main contigs and profile databases (we create a subset). This is because our initial contigs.be has too many splits (1,432,906 splits to be precise) and hierarchical clustering gets turned off.\n\nOnce it is splitted we can find a directory called \"denitrifications_splits\" in which we find a contigs and profile database that we can now plot using anvi-interactive:\n\n## anvi'o interactive plot - Denitrification - Nitrate reductase - Station 1\n\n![Anvi'o interactive plot](BIOPOLE_Chukchi_metaT_files/anvi_plot_dinitrification_nitrate_reductase.png){width=100%}\n\nNow we can start looking for specific genes and creating bins for each so we can visualise them and see their coverage.\n\n## KEGG Map of Nitrogen Pathways\n\n![KEGG map of Nitrogen metabolic pathways. Diagram from anvi'o and KEGG. In green are the genes present in anvio contig database for Station 1](BIOPOLE_Chukchi_metaT_files/Nitrogen_metabolism_St1_KEGG-1.png){width=100%}\n\n##  KEGG nitrogen cycle (map00910)\n\nThis is a standard, widely used KO set covering:\n\n- Nitrification\n- Denitrification\n- DNRA\n- Anammox\n- Nitrogen fixation\n\nAssimilatory pathways\n\n###  Core nitrogen-cycle KOs (map00910)\n- Nitrogen fixation\nK02588  nifH\nK02591  nifD\nK02586  nifK\n\n- Nitrification\nK10944  amoA\nK10945  amoB\nK10946  amoC\nK10535  hao\n\n- Assimilatory nitrate reduction\nK00367  nasA\nK00360  nirA\n\n- Dissimilatory nitrate reduction (DNRA)\nK00362  napA\nK00363  napB\nK00370  narG\nK00371  narH\nK00374  narI\nK02567  nrfA\nK02568  nrfH\n\n- Denitrification\nK00368  nirK\nK15864  nirS\nK04561  norB\nK02305  norC\nK00376  nosZ\n\n- Anammox\nK20932  hzsA\nK20933  hzsB\nK20934  hzsC\nK20935  hdh\n\n\n\n\n\n\n\n## Tara Oceans Arctic data as reference\n\n### Rationale and overview\n\nAs no site-matched metagenomic data were available for these samples, a reference-based approach was adopted using publicly available metagenomic data from the Tara Oceans Arctic expedition (**Station 194**), representing the closest comparable marine Arctic microbial communities currently available.\n\nThis strategy enables the detection and quantification of expressed genes that are conserved between Arctic marine microbial communities, while acknowledging that locally specific taxa or gene variants not present in the reference dataset may not be captured.\n\n### Assembly of Tara Oceans Arctic metagenomes\n\nRaw metagenomic reads from the Tara Oceans Arctic expedition were assembled de novo using **MEGAHIT**, which is optimized for large and complex metagenomic datasets. The resulting assembly produced a set of contigs representing microbial genomic fragments present in Arctic marine surface waters.\n\nThese contigs were subsequently used as a reference database for read mapping. While the Tara Oceans sampling locations do not overlap geographically with the Chukchi Sea, they provide a comprehensive representation of Arctic marine microbial diversity and metabolic potential, particularly for conserved biogeochemical pathways such as nitrogen cycling.\n\n### Metatranscriptomic read processing and mapping\n\nQuality-filtered metatranscriptomic reads were mapped to the Tara Oceans Arctic contigs using **Bowtie2** with default end-to-end alignment settings. Mapping was performed in paired-end mode to improve alignment specificity. Both concordant and discordant alignments were reported, although downstream analyses focused on concordantly mapped read pairs.\n\n**Mapping performance and alignment statistics**\n\nAcross samples, overall **alignment rates ranged from 15.8% to 27.3%** of paired-end reads mapping to the Tara Oceans Arctic contigs. The majority of reads aligned concordantly exactly once (11â€“18%), with a smaller proportion aligning to multiple locations (3â€“6%). Discordant alignments accounted for approximately 0.5â€“1% of read pairs.\n\nThese mapping rates are consistent with expectations for metatranscriptomic datasets mapped to non-site-matched metagenomic references, particularly in polar marine systems where microbial communities exhibit strong spatial structure and strain-level diversity. The observed alignment patterns suggest that a substantial fraction of expressed genes in the Chukchi Sea microbial community are shared with, or closely related to, those represented in the Tara Oceans Arctic metagenomes.\n\n**Interpretation and limitations**\n\nThis reference-based approach enables the identification and relative quantification of expressed genes that are conserved across Arctic marine microbial communities, including key genes involved in nitrogen cycling. However, transcripts derived from locally unique taxa or divergent gene variants absent from the Tara Oceans reference assembly are unlikely to be captured, resulting in an underestimation of total transcript diversity and expression.\n\nConsequently, analyses based on this approach focus on relative expression patterns of nitrogen-cycle gene families represented in the reference dataset, rather than absolute transcript abundances or the absence of specific metabolic pathways. Despite these limitations, the approach provides a robust framework for exploring nitrogen cycling activity in the Chukchi Sea in the absence of site-specific metagenomic data.\n\n",
    "supporting": [
      "BIOPOLE_Chukchi_metaT_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}